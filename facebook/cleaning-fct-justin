import pyspark
from csv import reader
import re
import pandas as pd
import datetime
from datetime import date
​
​
def build_data(drop = ["html", 'targetings', 'targeting', 'targetedness', "thumbnail", "page", 'lower_page', 'listbuilding_fundraising_proba']):
    '''
    Does preprocessing on the data and returns the "cleaned" dataframe. You can add any headers that you might want to drop.
​
    Returns the RDD of cleaned data as well as a dictionary who's keys are column headers and values are the index location in the corresponding row location.
    '''
    #First we drop the columns we don't want.
    my_df = spark.read.csv("/spring2020/data/fbpac-ads-en-US.csv", header = True, inferSchema = True, quote = "\"", escape = "\"")
    headers = ['id', 'html', 'political', 'not_political',
                        'title', 'message', 'thumbnail', 'created_at',
                        'updated_at', 'lang', 'images','impressions',
                        'political_probability', 'targeting', 'suppressed',
                        'targets', 'advertiser', 'entities', 'page',
                        'lower_page', 'targetings', 'paid_for_by',
                        'targetedness', 'listbuilding_fundraising_proba']
    for column in drop:
        my_df = my_df.drop(column)
        headers.remove(column)
    my_df = my_df.rdd.map(list)
    #This just defines the index that we'll return for users outside the function, and be utilized to clean the data
    hti = {y:x for (x,y) in enumerate(headers)}  # Header To Index
    functions = list()
    #
    #This entire section is just defining different cleaning functions on the different fields
    #
    if "id" in headers:
        def id_map(row):
            row[hti["id"]] = row[hti["id"]].strip("hyperfeed_story_id_")
            return row
        functions.append(id_map)
    #Converts the political column into all floats. If an error, changes it to "NA"
    if 'political' in headers:
        def political(row):
            try:
                index = hti['political']
                row[index] = float(row[index])
            except Exception as e:
                row[index] = "NA"
            return row
        functions.append(political)
    #Same for the "not_political" field
    if "not_political" in headers:
        def not_political(row):
            try:
                index = hti['not_political']
                row[index] = float(row[index])
            except Exception as e:
                row[index] = "NA"
            return row
        functions.append(not_political)
    # removes all the HTML elements and emojis from messages
    if 'message' in headers:
        def message_cleaner(row):
            '''
            Manda Bucklin wrote this function. I repurposed it
            '''
            fixupcontent = row[hti["message"]]
            try:
                fixupcontent = str(fixupcontent)
                clean = re.compile(r'<.*?>')
                fixupcontent1 = re.sub(clean, '', str(fixupcontent))
                emoji_pattern = re.compile("["
                u"\U0001F600-\U0001F64F" # emoticons
                u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                u"\U0001F680-\U0001F6FF"  # transport & map symbols
                u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                "]+", flags=re.UNICODE)
                fixupcontent2 = (emoji_pattern.sub(r'', str(fixupcontent1)))
                row[hti["message"]] = str(fixupcontent2)
            except Exception as e:
                row[hti["message"]] = "NA"
            return row
        functions.append(message_cleaner)
    #
    if "images" in headers:
        def process_images(row):
            image_string = row[hti['images']]
            try:
                reform = image_string.split(",")
                outta_here = {x.replace("{", "").replace("}", "").replace('"', "") for x in reform}
                row[hti["images"]] = outta_here
            except Exception as e:
                row[hti["images"]] = "NA"
            return row
        functions.append(process_images)
    if 'political_probability' in headers:
        def pol_prob(row):
            index = hti["political_probability"]
            try:
                row[index] = float(row[index])
            except Exception as e:
                row[index] = "NA"
            return row
        functions.append(pol_prob)
    #Here is where we actually map our RDD.
    if len(functions) == 0:
        pass
    else:
        def map_function(row):
            for fun in functions:
                row = fun(row)
            return row
        my_df = my_df.map(map_function)
    #Return our "cleaned" RDD and the header to index of the rows of the RDD
    return my_df, hti
